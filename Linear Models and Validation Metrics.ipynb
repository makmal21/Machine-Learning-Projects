{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92778525",
   "metadata": {},
   "source": [
    "# Linear Models and Validation Metrics\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce31b39a",
   "metadata": {},
   "source": [
    "### In this assignment, you will need to write code that uses linear models to perform classification and regression tasks. You will also be asked to describe the process by which you came up with the code. More details can be found below. Please cite any websites or AI tools that you used to help you with this assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c6de86",
   "metadata": {},
   "source": [
    "## Part 1: Classification \n",
    "\n",
    "You have been asked to develop code that can help the user determine if the email they have received is spam or not. Following the machine learning workflow described in class, write the relevant code in each of the steps below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3c6fc8",
   "metadata": {},
   "source": [
    "### Step 0: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33f86925",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9d33a8",
   "metadata": {},
   "source": [
    "### Step 1: Data Input\n",
    "\n",
    "The data used for this task can be downloaded using the yellowbrick library: \n",
    "https://www.scikit-yb.org/en/latest/api/datasets/spam.html\n",
    "\n",
    "Use the yellowbrick function `load_spam()` to load the spam dataset into the feature matrix `X` and target vector `y`.\n",
    "\n",
    "Print the size and type of `X` and `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33583c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of X is (4600, 57) and Size of y is (4600,)\n",
      "\n",
      "Type of X is <class 'pandas.core.frame.DataFrame'> \n",
      "Type of y is <class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "# TO DO: Import spam dataset from yellowbrick library\n",
    "from yellowbrick.datasets import load_spam\n",
    "X, y = load_spam() # X = feature matrix , y = target \n",
    "\n",
    "# TO DO: Print size and type of X and y\n",
    "print(\"Size of X is {} and Size of y is {}\".format(X.shape, y.shape))\n",
    "print(\"\\nType of X is {} \\nType of y is {}\".format(type(X), type(y)))  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156db208",
   "metadata": {},
   "source": [
    "### Step 2: Data Processing \n",
    "\n",
    "Check to see if there are any missing values in the dataset. If necessary, select an appropriate method to fill-in the missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e7204f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of null values in y dataset 0 \n",
      "Number of null values in X dataset \n",
      "word_freq_make                0\n",
      "word_freq_labs                0\n",
      "word_freq_857                 0\n",
      "word_freq_data                0\n",
      "word_freq_415                 0\n",
      "word_freq_85                  0\n",
      "word_freq_technology          0\n",
      "word_freq_1999                0\n",
      "word_freq_parts               0\n",
      "word_freq_pm                  0\n",
      "word_freq_direct              0\n",
      "word_freq_cs                  0\n",
      "word_freq_meeting             0\n",
      "word_freq_original            0\n",
      "word_freq_project             0\n",
      "word_freq_re                  0\n",
      "word_freq_edu                 0\n",
      "word_freq_table               0\n",
      "word_freq_conference          0\n",
      "char_freq_;                   0\n",
      "char_freq_(                   0\n",
      "char_freq_[                   0\n",
      "char_freq_!                   0\n",
      "char_freq_$                   0\n",
      "char_freq_#                   0\n",
      "capital_run_length_average    0\n",
      "capital_run_length_longest    0\n",
      "word_freq_telnet              0\n",
      "word_freq_lab                 0\n",
      "word_freq_address             0\n",
      "word_freq_650                 0\n",
      "word_freq_all                 0\n",
      "word_freq_3d                  0\n",
      "word_freq_our                 0\n",
      "word_freq_over                0\n",
      "word_freq_remove              0\n",
      "word_freq_internet            0\n",
      "word_freq_order               0\n",
      "word_freq_mail                0\n",
      "word_freq_receive             0\n",
      "word_freq_will                0\n",
      "word_freq_people              0\n",
      "word_freq_report              0\n",
      "word_freq_addresses           0\n",
      "word_freq_free                0\n",
      "word_freq_business            0\n",
      "word_freq_email               0\n",
      "word_freq_you                 0\n",
      "word_freq_credit              0\n",
      "word_freq_your                0\n",
      "word_freq_font                0\n",
      "word_freq_000                 0\n",
      "word_freq_money               0\n",
      "word_freq_hp                  0\n",
      "word_freq_hpl                 0\n",
      "word_freq_george              0\n",
      "capital_run_length_total      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# TO DO: Check if there are any missing values and fill them in if necessary\n",
    "\n",
    "#checked data type of each column - no object type\n",
    "X.dtypes\n",
    "y.dtypes\n",
    "\n",
    "#number of null values is 0\n",
    "X_null = X.isnull().sum().sort_values(ascending=False)\n",
    "y_null = y.isna().sum()\n",
    "\n",
    "print(\"Number of null values in y dataset {} \\nNumber of null values in X dataset \\n{}\".format(y_null, X_null))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a489285a",
   "metadata": {},
   "source": [
    "For this task, we want to test if the linear model would still work if we used less data. Use the `train_test_split` function from sklearn to create a new feature matrix named `X_small` and a new target vector named `y_small` that contain **5%** of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9bc4a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Create X_small and y_small \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_t, X_small, y_t, y_small = train_test_split(X, y, random_state=0, test_size=0.05)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e6c46f",
   "metadata": {},
   "source": [
    "### Step 3: Implement Machine Learning Model\n",
    "\n",
    "1. Import `LogisticRegression` from sklearn\n",
    "2. Instantiate model `LogisticRegression(max_iter=2000)`.\n",
    "3. Implement the machine learning model with three different datasets: \n",
    "    - `X` and `y`\n",
    "    - Only first two columns of `X` and `y`\n",
    "    - `X_small` and `y_small`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89f3d84",
   "metadata": {},
   "source": [
    "### Step 4: Validate Model\n",
    "\n",
    "Calculate the training and validation accuracy for the three different tests implemented in Step 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352106a3",
   "metadata": {},
   "source": [
    "### Step 5: Visualize Results \n",
    "\n",
    "1. Create a pandas DataFrame `results` with columns: Data size, training accuracy, validation accuracy\n",
    "2. Add the data size, training and validation accuracy for each dataset to the `results` DataFrame\n",
    "3. Print `results`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc070c51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data size</th>\n",
       "      <th>Training Accuracy</th>\n",
       "      <th>Validation Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>X</th>\n",
       "      <td>(4600, 57)</td>\n",
       "      <td>0.929</td>\n",
       "      <td>0.937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X_two_col</th>\n",
       "      <td>(4600, 2)</td>\n",
       "      <td>0.608</td>\n",
       "      <td>0.613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X_small</th>\n",
       "      <td>(230, 57)</td>\n",
       "      <td>0.965</td>\n",
       "      <td>0.793</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Data size  Training Accuracy  Validation Accuracy\n",
       "X          (4600, 57)              0.929                0.937\n",
       "X_two_col   (4600, 2)              0.608                0.613\n",
       "X_small     (230, 57)              0.965                0.793"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE FOR STEPS 3-5\n",
    "# Note: for any random state parameters, you can use random_state = 0\n",
    "# HINT: USING A LOOP TO STORE THE DATA IN YOUR RESULTS DATAFRAME WILL BE MORE EFFICIENT\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "results = pd.DataFrame(columns = ['Data size', 'Training Accuracy', 'Validation Accuracy'])\n",
    "X_two_col = X.iloc[:,:2]\n",
    "\n",
    "for X,y in zip([X, X_two_col, X_small],[y, y, y_small]):\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, random_state=0)\n",
    "    logreg = LogisticRegression(max_iter=2000).fit(X_train, y_train)\n",
    "    training_score = logreg.score(X_train, y_train)\n",
    "    validation_score = logreg.score(X_val, y_val)\n",
    "    \n",
    "    results.loc[len(results)]= [X.shape, training_score, validation_score]\n",
    "\n",
    "pd.set_option('display.precision', 3)\n",
    "results.index = ['X', 'X_two_col', 'X_small']\n",
    "display(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4427d4f",
   "metadata": {},
   "source": [
    "### Questions \n",
    "1. How do the training and validation accuracy change depending on the amount of data used? Explain with values.\n",
    "2. In this case, what do a false positive and a false negative represent? Which one is worse?\n",
    "\n",
    "*YOUR ANSWERS HERE*\n",
    "\n",
    "1.  \n",
    "\n",
    "For the largest dataset the training and validation scores are 0.93 and 0.94. The two scores are very close to 1 and to each other. Therefore, having a low variance and high bias (underfits).\n",
    "\n",
    "Smallest dataset(first two columns) the training and validation accuracy are both about 0.61 and the lowest score among the different datasets. The scores are almost the same, there is low variance. The validation score is far from the maximum R2 of 1, we have high bias. Since the model is only trained with a small dataset(only two features) the model doesn't see all the complexity of the data. Meaning the model made mistakes and is underfitting.\n",
    "\n",
    "For the 5% dataset(inbetween the other two sizes), the training score is 0.97 is very close to 1, a good score.  The validation score is 0.8. Only this dataset, has some difference between the validation and training score. Higher variance and low bias - overfits dataset. To decrease the variance a bit to bring up the validation score, we need more data.\n",
    "\n",
    "As the data size decreases, the validation score decreases as well (0.94, 0.79 and 0.61). For the largest and smallest dataset the training accuracy is high and around the same. The model is too simple for the smallest dataset. For the middle size dataset the validation score is to low. \n",
    "\n",
    "2. \n",
    "\n",
    "We are trying to identify spam, so positive class is spam and negative class is not spam. False Positive represents good mail that is marked as spam. False Negative is spam that is marked as not spam. \n",
    "\n",
    "False Positive is worse because you wouldn't want an important email to be marked as spam and not be able to recover or find it. Whereas for false negative you would be able to easily identify a spam email and delete it. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7559517a",
   "metadata": {},
   "source": [
    "### Process Description \n",
    "Please describe the process you used to create your code. Cite any websites or generative AI tools used. You can use the following questions as guidance:\n",
    "1. Where did you source your code?\n",
    "1. In what order did you complete the steps?\n",
    "1. If you used generative AI, what prompts did you use? Did you need to modify the code at all? Why or why not?\n",
    "1. Did you have any challenges? If yes, what were they? If not, what helped you to be successful?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fe687f",
   "metadata": {},
   "source": [
    "*DESCRIBE YOUR PROCESS HERE*\n",
    "\n",
    "1. I used the jupyter notebooks examples provided in labs/lectures and also referred to the textbooks for this class. I also used this website for importing the data :https://scikit-learn.org/. \n",
    "2. I read each step, reviewed the jupyter notebook examples then, I wrote the code. Ran the code to make sure it was working. If I had any problems, I would refer to the notes, textbook and jupyter notebooks. \n",
    "3. I used generative AI chatGPT to clarify concepts. Also, to look up functions. For example, I searched \"What is the difference between .score() and accuracy_score()?\" I didn't use any code from AI. \n",
    "4. The main challenge I faced was figuring out if the results of my model was correct and interpreting the results and looking for patterns. \n",
    "\n",
    "Sources Used \n",
    "- https://scikit-learn.org/\n",
    "- Chat GPT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4c78a8",
   "metadata": {},
   "source": [
    "## Part 2: Regression \n",
    "\n",
    "For this section, we will be evaluating concrete compressive strength of different concrete samples, based on age and ingredients. You will need to repeat the steps 1-4 from Part 1 for this analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ba83c5",
   "metadata": {},
   "source": [
    "### Step 1: Data Input\n",
    "\n",
    "The data used for this task can be downloaded using the yellowbrick library: \n",
    "https://www.scikit-yb.org/en/latest/api/datasets/concrete.html\n",
    "\n",
    "Use the yellowbrick function `load_concrete()` to load the spam dataset into the feature matrix `X` and target vector `y`.\n",
    "\n",
    "Print the size and type of `X` and `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6ff2e34f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of X is (1030, 8) and Size of y is (1030,)\n",
      "\n",
      "Type of X is <class 'pandas.core.frame.DataFrame'> \n",
      "Type of y is <class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "# TO DO: Import spam dataset from yellowbrick library\n",
    "\n",
    "from yellowbrick.datasets import load_concrete\n",
    "X, y  = load_concrete()  # X = feature matrix , y = target \n",
    "\n",
    "# TO DO: Print size and type of X and y\n",
    "\n",
    "print(\"Size of X is {} and Size of y is {}\".format(X.shape, y.shape))\n",
    "print(\"\\nType of X is {} \\nType of y is {}\".format(type(X), type(y)))  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5294cfa",
   "metadata": {},
   "source": [
    "### Step 2: Data Processing \n",
    "\n",
    "Check to see if there are any missing values in the dataset. If necessary, select an appropriate method to fill-in the missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "693c5fa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of null values in y dataset 0 \n",
      "Number of null values in X dataset \n",
      "cement    0\n",
      "slag      0\n",
      "ash       0\n",
      "water     0\n",
      "splast    0\n",
      "coarse    0\n",
      "fine      0\n",
      "age       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# TO DO: Check if there are any missing values and fill them in if necessary\n",
    "\n",
    "y.dtypes\n",
    "X.dtypes\n",
    "\n",
    "y_null = y.isnull().sum()\n",
    "X_null = X.isnull().sum().sort_values(ascending=False)\n",
    "\n",
    "#no null values found\n",
    "print(\"Number of null values in y dataset {} \\nNumber of null values in X dataset: \\n{}\".format(y_null, X_null))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc60489",
   "metadata": {},
   "source": [
    "### Step 3: Implement Machine Learning Model \n",
    "\n",
    "1. Import `LinearRegression` from sklearn\n",
    "2. Instantiate model `LinearRegression()`.\n",
    "3. Implement the machine learning model with `X` and `y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "b5041945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "# Note: for any random state parameters, you can use random_state = 0\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, random_state=0) \n",
    "\n",
    "lr = LinearRegression().fit(X_train,y_train)\n",
    "\n",
    "train_pred = lr.predict(X_train)\n",
    "val_pred = lr.predict(X_val) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de28482",
   "metadata": {},
   "source": [
    "### Step 4: Validate Model\n",
    "\n",
    "Calculate the training and validation accuracy using mean squared error and R2 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "970c038b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "#Mean squared Error score\n",
    "\n",
    "mse_t = mean_squared_error(y_train, train_pred)\n",
    "mse_v = mean_squared_error(y_val, val_pred)\n",
    "\n",
    "#R2 score\n",
    "\n",
    "r2score_t=r2_score(y_train, train_pred)\n",
    "r2score_v=r2_score(y_val, val_pred)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54aa7795",
   "metadata": {},
   "source": [
    "### Step 5: Visualize Results \n",
    "1. Create a pandas DataFrame `results` with columns: Training accuracy and Validation accuracy, and index: MSE and R2 score\n",
    "2. Add the accuracy results to the `results` DataFrame\n",
    "3. Print `results`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "88d223f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training Accuracy</th>\n",
       "      <th>Validation Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>111.36</td>\n",
       "      <td>95.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2</th>\n",
       "      <td>0.61</td>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Training Accuracy  Validation Accuracy\n",
       "MSE             111.36                95.90\n",
       "R2                0.61                 0.62"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "data = {'Training Accuracy': [mse_t,r2score_t ],'Validation Accuracy': [mse_v , r2score_v] }\n",
    "\n",
    "results = pd.DataFrame(data, index =['MSE', 'R2'], columns=['Training Accuracy', 'Validation Accuracy'])\n",
    "\n",
    "pd.set_option('display.precision', 2)\n",
    "display(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a42bda",
   "metadata": {},
   "source": [
    "### Questions \n",
    "1. Did using a linear model produce good results for this dataset? Why or why not?\n",
    "\n",
    "Based on the R2 score(the goodness of fit), there is low variance and high bias(many mistakes) between the training and validation score (0.61,0.62). This model is underfitting. Also, the training score(0.61) is low which indicates that the linear model did not produce good results and might be too simple for the data. We want a training accuracy that is higher then the validation accuracy and close to 1. \n",
    "\n",
    "Looking at the MSE, the MSE is very high for both training and validation, respectively. 111.4 & 95.9. This means the data points are more dispersed from the central mean, higher error and bad estimator. \n",
    "\n",
    "This model is a poor predicator for the training set and the unseen data with low R2 score and High MSE score. Therefore, a linear model did not produce good results. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca0ff2f",
   "metadata": {},
   "source": [
    "### Process Description \n",
    "Please describe the process you used to create your code. Cite any websites or generative AI tools used. You can use the following questions as guidance:\n",
    "1. Where did you source your code?\n",
    "1. In what order did you complete the steps?\n",
    "1. If you used generative AI, what prompts did you use? Did you need to modify the code at all? Why or why not?\n",
    "1. Did you have any challenges? If yes, what were they? If not, what helped you to be successful?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfdb0880",
   "metadata": {},
   "source": [
    "*DESCRIBE YOUR PROCESS HERE*\n",
    "\n",
    "1. I used the jupyter notebook class examples along with the lab exercises for the code. I also referred to class notes and the two textbooks for this class. \n",
    "2. I reviewed all my notes. Then, I attempted the steps in the assignment. To verify my code and results, I referred to the examples in the jupyter notebook specifically Linear Regression.\n",
    "3. I didn't use generative AI for this section. \n",
    "4. No I didn't have any challenges because a lot of the steps in this section were similar to the one above. Also, I reviewed examples in the notes to help me out. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72ac3eb",
   "metadata": {},
   "source": [
    "## Part 3: Observations/Interpretation \n",
    "\n",
    "Describe any pattern you see in the results. Relate your findings to what we discussed during lectures. Include data to justify your findings.\n",
    "\n",
    "\n",
    "*ADD YOUR FINDINGS HERE*\n",
    "\n",
    "For Classification model, the following patterns were seen: \n",
    "- For the largest dataset, both training(0.93) and validation(0.94) scores are high(close to 1). This indicates that when the dataset is large enough the scores stabilize and the model has learned the patterns in the data. Adding more data may not impact the accuracies as much. \n",
    "- For 5% of the data, the small dataset the training score is very high(0.97) but a low validation score of 0.79. This indicates the model has memorized the data but does not generalize to unseen data to the same degree. The model overfits the data( high variance, low bias).\n",
    "- For the smallest dataset(two columns), the training and validation scores are very low, same value of 0.61. The model is trained with only two features - less complex, too simple. The model does not learn all the patterns and also cannot predict results for new data. This model underfits the dataset with low variance and high bias. \n",
    "\n",
    "Overall, a certain amount of dataset is required while also capturing enough complexity of the model to predict good training and validation accuracy scores, R2 scores close to 1. We want a model that has a good balance between the two scores where it is able to learn the patterns in the training set and also able to generalize to unseen data to prevent underfitting or overfitting the data. \n",
    "\n",
    "For Regression model, the following patterns were seen: \n",
    "- The mean squared error for both training and validation was high : 111.36, 95.9. The MSE for validation score was slightly less. We want MSE to be as low as possible, since it indicates how much the predicted value deviates from the actual target value. In addition, the R2 score was relatively low for both training(0.61) and validation score(0.62) which is far from the maximum of 1. These scores indicate that the linear model is too simple for this dataset. The dataset needs a more complex model to capture its patterns. This linear model underfit the dataset, low variance and high bias(makes mistakes).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b84eed",
   "metadata": {},
   "source": [
    "## Part 4: Reflection \n",
    "Include a sentence or two about:\n",
    "- what you liked or disliked,\n",
    "- found interesting, confusing, challangeing, motivating\n",
    "while working on this assignment.\n",
    "\n",
    "\n",
    "*ADD YOUR THOUGHTS HERE*\n",
    "\n",
    "I liked that the questions were seperated into steps which made it easier to work through and write the code. I also enjoyed using juptyer notebook for the assignment as each step could be tested seperately. \n",
    "I found it challenging at first when using the different python functions since there are multiple ways of doing a lot of the same things and certain functions only work with certain data types. I found the data sets interesting and I found it interesting to see how the models performed based on the dataset size. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db951b3a",
   "metadata": {},
   "source": [
    "## Part 5: Bonus Question \n",
    "\n",
    "Repeat Part 2 with Ridge and Lasso regression to see if you can improve the accuracy results. Which method and what value of alpha gave you the best R^2 score? Is this score \"good enough\"? Explain why or why not.\n",
    "\n",
    "**Remember**: Only test values of alpha from 0.001 to 100 along the logorithmic scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "47623d44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso Linear Model Results\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training Accuracy MSE</th>\n",
       "      <th>Validation Accuracy MSE</th>\n",
       "      <th>Training Accuracy R2</th>\n",
       "      <th>Validation Accuracy R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.001</th>\n",
       "      <td>111.358</td>\n",
       "      <td>95.904</td>\n",
       "      <td>0.611</td>\n",
       "      <td>0.623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.01</th>\n",
       "      <td>111.358</td>\n",
       "      <td>95.900</td>\n",
       "      <td>0.611</td>\n",
       "      <td>0.623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.1</th>\n",
       "      <td>111.359</td>\n",
       "      <td>95.867</td>\n",
       "      <td>0.611</td>\n",
       "      <td>0.624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>111.420</td>\n",
       "      <td>95.585</td>\n",
       "      <td>0.611</td>\n",
       "      <td>0.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.0</th>\n",
       "      <td>113.221</td>\n",
       "      <td>95.049</td>\n",
       "      <td>0.604</td>\n",
       "      <td>0.627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100.0</th>\n",
       "      <td>152.347</td>\n",
       "      <td>125.446</td>\n",
       "      <td>0.468</td>\n",
       "      <td>0.507</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Training Accuracy MSE  Validation Accuracy MSE  Training Accuracy R2  \\\n",
       "0.001                111.358                   95.904                 0.611   \n",
       "0.01                 111.358                   95.900                 0.611   \n",
       "0.1                  111.359                   95.867                 0.611   \n",
       "1.0                  111.420                   95.585                 0.611   \n",
       "10.0                 113.221                   95.049                 0.604   \n",
       "100.0                152.347                  125.446                 0.468   \n",
       "\n",
       "       Validation Accuracy R2  \n",
       "0.001                   0.623  \n",
       "0.01                    0.623  \n",
       "0.1                     0.624  \n",
       "1.0                     0.625  \n",
       "10.0                    0.627  \n",
       "100.0                   0.507  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Linear Model Results\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training Accuracy MSE</th>\n",
       "      <th>Validation Accuracy MSE</th>\n",
       "      <th>Training Accuracy R2</th>\n",
       "      <th>Validation Accuracy R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.001</th>\n",
       "      <td>111.358</td>\n",
       "      <td>95.904</td>\n",
       "      <td>0.611</td>\n",
       "      <td>0.623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.01</th>\n",
       "      <td>111.358</td>\n",
       "      <td>95.904</td>\n",
       "      <td>0.611</td>\n",
       "      <td>0.623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.1</th>\n",
       "      <td>111.358</td>\n",
       "      <td>95.904</td>\n",
       "      <td>0.611</td>\n",
       "      <td>0.623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>111.358</td>\n",
       "      <td>95.904</td>\n",
       "      <td>0.611</td>\n",
       "      <td>0.623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.0</th>\n",
       "      <td>111.358</td>\n",
       "      <td>95.903</td>\n",
       "      <td>0.611</td>\n",
       "      <td>0.623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100.0</th>\n",
       "      <td>111.359</td>\n",
       "      <td>95.894</td>\n",
       "      <td>0.611</td>\n",
       "      <td>0.623</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Training Accuracy MSE  Validation Accuracy MSE  Training Accuracy R2  \\\n",
       "0.001                111.358                   95.904                 0.611   \n",
       "0.01                 111.358                   95.904                 0.611   \n",
       "0.1                  111.358                   95.904                 0.611   \n",
       "1.0                  111.358                   95.904                 0.611   \n",
       "10.0                 111.358                   95.903                 0.611   \n",
       "100.0                111.359                   95.894                 0.611   \n",
       "\n",
       "       Validation Accuracy R2  \n",
       "0.001                   0.623  \n",
       "0.01                    0.623  \n",
       "0.1                     0.623  \n",
       "1.0                     0.623  \n",
       "10.0                    0.623  \n",
       "100.0                   0.623  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "\n",
    "\n",
    "from sklearn.linear_model import Lasso, Ridge\n",
    "results = pd.DataFrame(columns=['Training Accuracy MSE', 'Validation Accuracy MSE',\n",
    "                                'Training Accuracy R2', 'Validation Accuracy R2' ])\n",
    "\n",
    "#Lasso\n",
    "values = [0.001, 0.01, 0.1, 1.0, 10.0, 100.0]\n",
    "for alpha in values:\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, random_state=0) \n",
    "    lasso_model = Lasso(alpha= alpha).fit(X_train,y_train)\n",
    "\n",
    "    train_pred = lasso_model.predict(X_train)\n",
    "    val_pred = lasso_model.predict(X_val) \n",
    "\n",
    "    mse_t = mean_squared_error(y_train, train_pred)\n",
    "    mse_v = mean_squared_error(y_val, val_pred)\n",
    "\n",
    "    r2score_t=r2_score(y_train, train_pred)\n",
    "    r2score_v=r2_score(y_val, val_pred)\n",
    "\n",
    "    results.loc[len(results)]= [mse_t, mse_v, r2score_t, r2score_v]\n",
    "\n",
    "results.index =['0.001', '0.01', '0.1', '1.0', '10.0', '100.0'] \n",
    "pd.set_option('display.precision', 3)\n",
    "print('Lasso Linear Model Results')\n",
    "display(results)\n",
    "\n",
    "results2 = pd.DataFrame(columns=['Training Accuracy MSE', 'Validation Accuracy MSE',\n",
    "                                'Training Accuracy R2', 'Validation Accuracy R2' ])\n",
    "#Ridge\n",
    "values = [0.001, 0.01, 0.1, 1.0, 10.0, 100.0]\n",
    "for alpha in values:\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, random_state=0) \n",
    "    ridge_model = Ridge(alpha= alpha).fit(X_train,y_train)\n",
    "\n",
    "    train_pred = ridge_model.predict(X_train)\n",
    "    val_pred = ridge_model.predict(X_val) \n",
    "\n",
    "    mse_t = mean_squared_error(y_train, train_pred)\n",
    "    mse_v = mean_squared_error(y_val, val_pred)\n",
    "\n",
    "    r2score_t=r2_score(y_train, train_pred)\n",
    "    r2score_v=r2_score(y_val, val_pred)\n",
    "\n",
    "    #r2score_t=r2_score(y_train, train_pred)\n",
    "    #r2score_v=r2_score(y_val, val_pred)\n",
    "\n",
    "    results2.loc[len(results2)]= [mse_t, mse_v, r2score_t, r2score_v]\n",
    "\n",
    "results2.index =['0.001', '0.01', '0.1', '1.0', '10.0', '100.0'] \n",
    "pd.set_option('display.precision', 3)\n",
    "print('Ridge Linear Model Results')\n",
    "display(results2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b606236",
   "metadata": {},
   "source": [
    "*ANSWER HERE*\n",
    "\n",
    "In general, we choose the alpha value that results in the highest validation score. \n",
    "\n",
    "Ridge linear model gave the same results as Linear regression with varying alpha values. \n",
    "For lasso model, the values were about the same for alpha values from 0.001 to 1. For alpha values of 10 and 100 the model performed worse since most features are removed by bringing it to zero. No alpha value gave the best score and this score is not good enough since training score is less then validation score and both very low. Linear model is not a good fit for this dataset therefore changing the alpha value makes no difference for either model. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
