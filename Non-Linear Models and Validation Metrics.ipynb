{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92778525",
   "metadata": {},
   "source": [
    "# Non-Linear Models and Validation Metrics \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce31b39a",
   "metadata": {},
   "source": [
    "### In this assignment, you will need to write code that uses non-linear models to perform classification and regression tasks. You will also be asked to describe the process by which you came up with the code. More details can be found below. Please cite any websites or AI tools that you used to help you with this assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf275ca7",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b67a661",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee2d2c3",
   "metadata": {},
   "source": [
    "## Part 1: Regression \n",
    "\n",
    "For this section, we will be continuing with the concrete example from yellowbrick. You will need to compare these results to the results from the previous assignment. Please use the results from the solution if you were unable to complete Assignment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8219f163",
   "metadata": {},
   "source": [
    "### Step 1: Data Input \n",
    "\n",
    "The data used for this task can be downloaded using the yellowbrick library: \n",
    "https://www.scikit-yb.org/en/latest/api/datasets/concrete.html\n",
    "\n",
    "Use the yellowbrick function `load_concrete()` to load the concrete dataset into the feature matrix `X` and target vector `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2af8bd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Import concrete dataset from yellowbrick library\n",
    "\n",
    "from yellowbrick.datasets import load_concrete\n",
    "\n",
    "X,y = load_concrete()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fea4cc",
   "metadata": {},
   "source": [
    "### Step 2: Data Processing\n",
    "\n",
    "Data processing was completed in the previous assignment. No need to repeat here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a245d00",
   "metadata": {},
   "source": [
    "### Step 3: Implement Machine Learning Model\n",
    "\n",
    "1. Import the Decision Tree, Random Forest and Gradient Boosting Machines regression models from sklearn\n",
    "2. Instantiate the three models with `max_depth = 5`. Are there any other parameters that you will need to set?\n",
    "3. Implement each machine learning model with `X` and `y`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f994e31",
   "metadata": {},
   "source": [
    "### Step 4: Validate Model\n",
    "\n",
    "Calculate the average training and validation accuracy using mean squared error with cross-validation. To do this, you will need to set `scoring='neg_mean_squared_error'` in your `cross_validate` function and negate the results (multiply by -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc3f7a8",
   "metadata": {},
   "source": [
    "### Step 5: Visualize Results \n",
    "\n",
    "1. Create a pandas DataFrame `results` with columns: Training accuracy and Validation accuracy, and index: DT, RF and GB\n",
    "2. Add the accuracy results to the `results` DataFrame\n",
    "3. Print `results`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fdc93a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training accuracy</th>\n",
       "      <th>Validation accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DT</th>\n",
       "      <td>47.28</td>\n",
       "      <td>73.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>29.58</td>\n",
       "      <td>45.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GB</th>\n",
       "      <td>3.38</td>\n",
       "      <td>22.82</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Training accuracy  Validation accuracy\n",
       "DT              47.28                73.45\n",
       "RF              29.58                45.05\n",
       "GB               3.38                22.82"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE FOR STEPS 3-5\n",
    "# Note: for any random state parameters, you can use random_state = 0\n",
    "# HINT: USING A LOOP TO STORE THE DATA IN YOUR RESULTS DATAFRAME WILL BE MORE EFFICIENT\n",
    "#1. \n",
    "from sklearn.tree import DecisionTreeRegressor \n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import cross_validate, cross_val_predict\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    " \n",
    "DT_model = DecisionTreeRegressor(max_depth = 5, random_state=0)\n",
    "#DT_model.fit(X_train, y_train)\n",
    "\n",
    "RF_model = RandomForestRegressor(max_depth = 5, random_state=0)\n",
    "#RF_model.fit(X_train, y_train)\n",
    "\n",
    "GB_model = GradientBoostingRegressor(max_depth = 5, random_state=0)\n",
    "#GB_model.fit(X_train, y_train)\n",
    "\n",
    "results = pd.DataFrame(columns=[\"Training accuracy\", \"Validation accuracy\"])\n",
    "models= [DT_model,RF_model, GB_model]\n",
    "\n",
    "#use X_train so test can be used for confusion metrics \n",
    "for model in models:\n",
    "    scores = cross_validate(model, X_train, y_train, cv=5, \n",
    "                            scoring='neg_mean_squared_error',\n",
    "                        return_train_score=True)\n",
    "    train_score = scores['train_score'].mean()*-1\n",
    "    validation_score = scores['test_score'].mean()*-1\n",
    "    results.loc[len(results)]= [train_score, validation_score]\n",
    "\n",
    "\n",
    "pd.set_option('display.precision', 2)\n",
    "results.index = [\"DT\", \"RF\", \"GB\"]\n",
    "print(\"Mean Squared Error\")\n",
    "display(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31715a9d",
   "metadata": {},
   "source": [
    "Repeat the step above to print the R2 score instead of the mean-squared error. For this case, you can use `scoring='r2'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83539f47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 Score\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training accuracy</th>\n",
       "      <th>Validation accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DT</th>\n",
       "      <td>0.83</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>0.90</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GB</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Training accuracy  Validation accuracy\n",
       "DT               0.83                 0.74\n",
       "RF               0.90                 0.84\n",
       "GB               0.99                 0.92"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training accuracy</th>\n",
       "      <th>Validation accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DT</th>\n",
       "      <td>47.28</td>\n",
       "      <td>73.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>29.58</td>\n",
       "      <td>45.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GB</th>\n",
       "      <td>3.38</td>\n",
       "      <td>22.82</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Training accuracy  Validation accuracy\n",
       "DT              47.28                73.45\n",
       "RF              29.58                45.05\n",
       "GB               3.38                22.82"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "\n",
    "models= [DT_model,RF_model, GB_model]\n",
    "results_r2 = pd.DataFrame(columns=[\"Training accuracy\", \"Validation accuracy\"])\n",
    "for model in models:\n",
    "    scores2 = cross_validate(model, X_train, y_train, cv=5, \n",
    "                            scoring='r2',\n",
    "                        return_train_score=True)\n",
    "    train_score2 = scores2['train_score'].mean()\n",
    "    validation_score2 = scores2['test_score'].mean()\n",
    "    results_r2.loc[len(results_r2)]= [train_score2, validation_score2]\n",
    "\n",
    "\n",
    "pd.set_option('display.precision', 2)\n",
    "results_r2.index = [\"DT\", \"RF\", \"GB\"]\n",
    "print(\"r2 Score\")\n",
    "display(results_r2)\n",
    "print(\"Mean Squared Error\")\n",
    "display(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5257a98",
   "metadata": {},
   "source": [
    "### Questions \n",
    "1. How do these results compare to the results using a linear model in the previous assignment? Use values.\n",
    "2. Out of the models you tested, which model would you select for this dataset and why?\n",
    "3. If you wanted to increase the accuracy of the tree-based models, what would you do? Provide two suggestions.\n",
    "\n",
    "*ANSWER HERE*\n",
    "\n",
    "1. \n",
    "Linear model results:  MSE train 111.36,\tMSE Validation 95.90, R2 train 0.61, R2 Validation 0.62. \n",
    "    The linear model had a greater MSE and lower accuracy then nonlinear models. Linear model was underfitting the dataset with (low variance and high bias), the model wasn't complex enough. \n",
    "\n",
    "Using non-linear model : \n",
    "    Overall, the non linear tree based models resulted in higher training accuracy (0.83, 0.9, 0.99) and higher validations score(0.74, 0.84, 0.92), smaller mean squared error then the linear model. The tree based models have high variance and low bias, overfitting the dataset. \n",
    "\n",
    "The dataset is more suited for a non-linear model which is evident through the results as we want smallest MSE and r2 score close to 1.\n",
    "\n",
    "\n",
    "2. I would select the gradiant boosting regressor because it has the highest training(0.99) and validation(0.92) r2 score. Also, the mean squared error is the lowest for this model for both training MSE(3.38) and validation MSE (22.82). We want r2 score to be closest to 1 and smallest mean squared error - which is achieved by the gradiant boosting regressor. This model generalizes the data well and also would be able to predict unseen data. \n",
    "\n",
    "3. To increase the validation accuracy we would need to make the model less complex since they are overfitting(high variance, low bias):\n",
    "    - pre-pruning by reducing the maximum depth \n",
    "    - create more trees, increasing n_estimator for random forest \n",
    "    - use smaller max_features \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b238f4",
   "metadata": {},
   "source": [
    "### Process Description \n",
    "Please describe the process you used to create your code. Cite any websites or generative AI tools used. You can use the following questions as guidance:\n",
    "1. Where did you source your code?\n",
    "1. In what order did you complete the steps?\n",
    "1. If you used generative AI, what prompts did you use? Did you need to modify the code at all? Why or why not?\n",
    "1. Did you have any challenges? If yes, what were they? If not, what helped you to be successful?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93097bfe",
   "metadata": {},
   "source": [
    "*DESCRIBE YOUR PROCESS HERE*\n",
    "1. I referred to assignment 2 solutions as well as Decision tree example juptyer notebook for code sourcing. \n",
    "2. I reviewed the notes. Then, I attempted the question in the order presented while referring to class material. \n",
    "3. I didn't use generative AI for this section. \n",
    "4. I didn't have any challenges and what helped was reading through class material first before starting the assignment. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c6de86",
   "metadata": {},
   "source": [
    "## Part 2: Classification \n",
    "\n",
    "You have been asked to develop code that can help the user classify different wine samples. Following the machine learning workflow described in class, write the relevant code in each of the steps below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9d33a8",
   "metadata": {},
   "source": [
    "### Step 1: Data Input\n",
    "\n",
    "The data used for this task can be downloaded from UCI: https://archive.ics.uci.edu/dataset/109/wine\n",
    "\n",
    "Use the pandas library to load the dataset. You must define the column headers if they are not included in the dataset \n",
    "\n",
    "You will need to split the dataset into feature matrix `X` and target vector `y`. Which column represents the target vector?\n",
    "\n",
    "Print the size and type of `X` and `y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33583c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of X is (178, 13) and  Size of y is (178,)\n",
      "\n",
      "Type of X is <class 'pandas.core.frame.DataFrame'> \n",
      "Type of y is <class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "# TO DO: Import wine dataset\n",
    "\n",
    "data = pd.read_csv(\"wine.data\",na_values='?', names=[\"class\",\"Alcohol\", \"Malic acid\", \"Ash\",\n",
    "                                    \"Alcalinity of ash\",\"Magnesium\", \n",
    "                                    \"Total phenols\", \"Flavanoids\",\"Nonflavanoid phenols\", \n",
    "                                    \"Proanthocyanins\",\"Color intensity\", \n",
    "                                    \"Hue\",\"OD280/OD315 of diluted wines\",\"Proline\"])\n",
    "\n",
    "#data.info()\n",
    "X = data.drop(columns = 'class')\n",
    "y = data['class']\n",
    "\n",
    "print(\"Size of X is {} and  Size of y is {}\".format(X.shape, y.shape))\n",
    "print(\"\\nType of X is {} \\nType of y is {}\".format(type(X), type(y)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156db208",
   "metadata": {},
   "source": [
    "### Step 2: Data Processing "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28af110",
   "metadata": {},
   "source": [
    "Print the first five rows of the dataset to inspect:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea266921",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Malic acid</th>\n",
       "      <th>Ash</th>\n",
       "      <th>Alcalinity of ash</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>Total phenols</th>\n",
       "      <th>Flavanoids</th>\n",
       "      <th>Nonflavanoid phenols</th>\n",
       "      <th>Proanthocyanins</th>\n",
       "      <th>Color intensity</th>\n",
       "      <th>Hue</th>\n",
       "      <th>OD280/OD315 of diluted wines</th>\n",
       "      <th>Proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class  Alcohol  Malic acid   Ash  Alcalinity of ash  Magnesium  \\\n",
       "0      1    14.23        1.71  2.43               15.6        127   \n",
       "1      1    13.20        1.78  2.14               11.2        100   \n",
       "2      1    13.16        2.36  2.67               18.6        101   \n",
       "3      1    14.37        1.95  2.50               16.8        113   \n",
       "4      1    13.24        2.59  2.87               21.0        118   \n",
       "\n",
       "   Total phenols  Flavanoids  Nonflavanoid phenols  Proanthocyanins  \\\n",
       "0           2.80        3.06                  0.28             2.29   \n",
       "1           2.65        2.76                  0.26             1.28   \n",
       "2           2.80        3.24                  0.30             2.81   \n",
       "3           3.85        3.49                  0.24             2.18   \n",
       "4           2.80        2.69                  0.39             1.82   \n",
       "\n",
       "   Color intensity   Hue  OD280/OD315 of diluted wines  Proline  \n",
       "0             5.64  1.04                          3.92     1065  \n",
       "1             4.38  1.05                          3.40     1050  \n",
       "2             5.68  1.03                          3.17     1185  \n",
       "3             7.80  0.86                          3.45     1480  \n",
       "4             4.32  1.04                          2.93      735  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834fc8fe",
   "metadata": {},
   "source": [
    "Check to see if there are any missing values in the dataset. If necessary, select an appropriate method to fill-in the missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97c6e9dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class                           0\n",
       "Alcohol                         0\n",
       "Malic acid                      0\n",
       "Ash                             0\n",
       "Alcalinity of ash               0\n",
       "Magnesium                       0\n",
       "Total phenols                   0\n",
       "Flavanoids                      0\n",
       "Nonflavanoid phenols            0\n",
       "Proanthocyanins                 0\n",
       "Color intensity                 0\n",
       "Hue                             0\n",
       "OD280/OD315 of diluted wines    0\n",
       "Proline                         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "data.isnull().sum()\n",
    "\n",
    "#no missing values "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070956af",
   "metadata": {},
   "source": [
    "How many samples do we have of each type of wine?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b37a6fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 1 has 59 samples\n",
      "Class 2 has 71 samples\n",
      "Class 3 has 48 samples\n"
     ]
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "\n",
    "\"\"\" data_2 = data.groupby(by= \"class\").count().Alcohol\n",
    "data_2.iloc[0]\n",
    "display(data_2)\n",
    "y.value_counts()[type] - another way to do it \n",
    "print(\"Class 1 has {}, Class 2 has {} and Class 3 has {} samples\".format(data_2.iloc[0], data_2.iloc[1], data_2.iloc[2])) \"\"\"\n",
    "\n",
    "type_wine = set(y.values)\n",
    "\n",
    "for type in type_wine: \n",
    "    print(\"Class {} has {} samples\". format(type,(y==type).sum()))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e6c46f",
   "metadata": {},
   "source": [
    "### Step 3: Implement Machine Learning Model\n",
    "\n",
    "1. Import `SVC` and `DecisionTreeClassifier` from sklearn\n",
    "2. Instantiate models as `SVC()` and `DecisionTreeClassifier(max_depth = 3)`\n",
    "3. Implement the machine learning model with `X` and `y`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0870b0d2",
   "metadata": {},
   "source": [
    "### Step 4: Validate Model \n",
    "\n",
    "Calculate the average training and validation accuracy using `cross_validate` for the two different models listed in Step 3. For this case, use `scoring='accuracy'`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0bbd83",
   "metadata": {},
   "source": [
    "### Step 5: Visualize Results \n",
    "\n",
    "#### Step 5.1: Compare Models\n",
    "1. Create a pandas DataFrame `results` with columns: Training accuracy and Validation accuracy\n",
    "2. Add the data size, training and validation accuracy for each dataset to the `results` DataFrame\n",
    "3. Print `results`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be4b5c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data Size X</th>\n",
       "      <th>Data Size y</th>\n",
       "      <th>Training accuracy</th>\n",
       "      <th>Validation accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DTC</th>\n",
       "      <td>(133, 13)</td>\n",
       "      <td>(133,)</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>(133, 13)</td>\n",
       "      <td>(133,)</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Data Size X Data Size y  Training accuracy  Validation accuracy\n",
       "DTC   (133, 13)      (133,)               0.97                 0.87\n",
       "SVC   (133, 13)      (133,)               0.71                 0.68"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE FOR STEPS 3-5\n",
    "# Note: for any random state parameters, you can use random_state = 0\n",
    "# HINT: USING A LOOP TO STORE THE DATA IN YOUR RESULTS DATAFRAME WILL BE MORE EFFICIENT\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC \n",
    "#stratify=y\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=0)\n",
    "\n",
    "DTC_model = DecisionTreeClassifier(max_depth = 3, random_state=0)\n",
    "DTC_model.fit(X_train, y_train)\n",
    "\n",
    "svc_model = SVC()\n",
    "#svc_model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "results = pd.DataFrame(columns=[\"Data Size X\",\"Data Size y\",\"Training accuracy\", \"Validation accuracy\"])\n",
    "models= [DTC_model, svc_model]\n",
    "\n",
    "for model in models:\n",
    "    scores = cross_validate(model, X_train, y_train, cv=5, \n",
    "                            scoring='accuracy',\n",
    "                        return_train_score=True)\n",
    "    train_score = scores['train_score'].mean()\n",
    "    validation_score = scores['test_score'].mean()\n",
    "    results.loc[len(results)]= [X_train.shape, y_train.shape, train_score, validation_score]\n",
    "\n",
    "\n",
    "pd.set_option('display.precision', 2)\n",
    "results.index = [\"DTC\",\"SVC\"]\n",
    "print(\"Accuracy Score\")\n",
    "display(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e17878",
   "metadata": {},
   "source": [
    "#### Step 5.2: Visualize Classification Errors\n",
    "Which method gave the highest accuracy? Use this method to print the confusion matrix and classification report:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44b091a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Implement best model \n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred = DTC_model.predict(X_test)\n",
    "mat = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "#best model: Decision Tree Model \n",
    "#y_pred = cross_val_predict(DTC_model, X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09d21b59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(145.22222222222229, 0.5, 'true value')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x550 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TO DO: Print confusion matrix using a heatmap\n",
    "labels=['Class 1','Class 2', 'Class 3']\n",
    "\n",
    "import seaborn as sns\n",
    "sns.heatmap(mat,xticklabels=labels,  yticklabels=labels, square=True, annot=True)\n",
    "plt.xlabel('predicted value')\n",
    "plt.ylabel('true value')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ef95947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 1       0.90      0.60      0.72        15\n",
      "     Class 2       0.71      0.94      0.81        18\n",
      "     Class 3       1.00      0.92      0.96        12\n",
      "\n",
      "    accuracy                           0.82        45\n",
      "   macro avg       0.87      0.82      0.83        45\n",
      "weighted avg       0.85      0.82      0.82        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TO DO: Print classification report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred, \n",
    "                            target_names=labels, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf319621",
   "metadata": {},
   "source": [
    "### Questions \n",
    "1. How do the training and validation accuracy change depending on the method used? Explain with values.\n",
    "2. What are two reasons why the support vector machines model did not work as well as the tree-based model?\n",
    "3. How many samples were incorrectly classified in step 5.2? \n",
    "4. In this case, is maximizing precision or recall more important? Why?\n",
    "\n",
    "*YOUR ANSWERS HERE*\n",
    "\n",
    "1. Decision tree classifier has a very high training accuracy (0.97) and a validation score of 0.87. There is high variance and low bias so this model overfits the data. The training accuracy is almost 1 which means the model is complex and likely memorizes the data. \n",
    "The support vector classifier results in low training and validation accuracy with low variance as the values are about the same of 0.71 & 0.68. This indicates that the model is underfitting and not complex enough.\n",
    "\n",
    "2. The support vector machine model didn't work as well since this model requires careful preprocessing of data(scaling) and tuning of the parameters. No parameters were specified. Specifying the C and gamma hyperparameter could help make this model perform better. \n",
    "\n",
    "3. Samples incorrectly classified are 8 samples.  \n",
    "6(classified as class 2 but class 1) + 1(classfied as class 2 but class 3)+ 1(classfied as class 1 but class 2) = 8. \n",
    "\n",
    "4. Precision indicates that we have no false positives. Recall indicates we have no false negatives. In this case, it doesn't matter as much which value we maximize since classifyling three different types of wine is low stakes. \n",
    "\n",
    "precision : how many predicted positive are actually positive : TP/TP+FP\n",
    "recall: how many actual positives did we catch TP/TP+FN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664ff8ae",
   "metadata": {},
   "source": [
    "### Process Description \n",
    "Please describe the process you used to create your code. Cite any websites or generative AI tools used. You can use the following questions as guidance:\n",
    "1. Where did you source your code?\n",
    "1. In what order did you complete the steps?\n",
    "1. If you used generative AI, what prompts did you use? Did you need to modify the code at all? Why or why not?\n",
    "1. Did you have any challenges? If yes, what were they? If not, what helped you to be successful?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e837da",
   "metadata": {},
   "source": [
    "*DESCRIBE YOUR PROCESS HERE*\n",
    "1. I sourced my code from the class examples - the jupyter notbook for decision trees. \n",
    "2. I reviewed the notes, attempted the assignment in the steps provided and then referred to notes if I got stuck. \n",
    "3. I didn't use generative AI. \n",
    "4. I had a bit of challenge loading the dataset. I was getting parse errors and then errors because the file was not in the folder directly. \n",
    "Once I figured out the problem, there were no other challenges "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd7358d",
   "metadata": {},
   "source": [
    "## Part 3: Observations/Interpretation \n",
    "\n",
    "Describe any pattern you see in the results. Relate your findings to what we discussed during lectures. Include data to justify your findings.\n",
    "\n",
    "\n",
    "*ADD YOUR FINDINGS HERE*\n",
    "\n",
    "Discussed in lectures: \n",
    "Main drawback of decision trees is that they tend to overfit the training data. Ensembles of decision trees \n",
    "reduce the amount of overfitting by averaging the trees and for gradient boosting. \n",
    "\n",
    "For classification, SVM require tuning and scaling of data to perform well.  \n",
    "\n",
    "Regression: \n",
    "\n",
    "Decision Tree resulted in high variance and low bias (training: 0.83, validation: 0.74), the model is overfitting too complex. Low validation score.\n",
    "\n",
    "Random forest model resulted in a higher traning accuracy (0.9) and higher validation accuracy (0.84) in comparison to Decision Tree model . The increase in validation accuracy is due to using many decision trees and averaging them. \n",
    "\n",
    "Gradient Boosting model resulted in highest training accuracy (0.99) and highest validation accuracy (0.92) and lowest MSE in comparison to two other models. This model had the best results as it uses many trees and corrects the mistakes of the tree built before in series. \n",
    "\n",
    "Overall, results agree with the theory learned in class.  \n",
    "\n",
    "Classification: \n",
    "\n",
    "- Decision tree classifier has a very high training accuracy (0.97) and a high validation score of 0.87. There is high variance and low bias so this model overfits the data. \n",
    "- SVC resulted in low training(0.71) and validation accuracy(0.68) with low variance as the values are about the same. This indicates that the model is underfitting and is too simple. Model didn't perform as well, its not able to generalize or predict unseen data( makes mistakes). SVC can be improved by tuning parameters and scaling data. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd97b6ac",
   "metadata": {},
   "source": [
    "## Part 4: Reflection \n",
    "Include a sentence or two about:\n",
    "- what you liked or disliked,\n",
    "- found interesting, confusing, challangeing, motivating\n",
    "while working on this assignment.\n",
    "\n",
    "\n",
    "*ADD YOUR THOUGHTS HERE*\n",
    "\n",
    "I liked that the assignment is split into steps and that it is in juptyer notebook. This makes it easier to execute what is being asked and visualizing the results of the code\n",
    "in segments has helped with understanding the content better. \n",
    "\n",
    "I found it interesting to read about the datasets and the features that are being used. Some of the questions wording can be confusing or hard to decipher what is being asked. For example, at first I interrupted data size as the total number of data samples but realized it was asking for the shape. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa21e53b",
   "metadata": {},
   "source": [
    "## Part 5: Bonus Question \n",
    "\n",
    "Repeat Part 2 and compare the support vector machines model used to `LinearSVC(max_iter=5000)`. Does using `LinearSVC` improve the results? Why or why not?\n",
    "\n",
    "Is `LinearSVC` a good fit for this dataset? Why or why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "854e952c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mehreen/anaconda3/envs/ensf-ml/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/mehreen/anaconda3/envs/ensf-ml/lib/python3.10/site-packages/sklearn/svm/_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/mehreen/anaconda3/envs/ensf-ml/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/mehreen/anaconda3/envs/ensf-ml/lib/python3.10/site-packages/sklearn/svm/_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/mehreen/anaconda3/envs/ensf-ml/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/mehreen/anaconda3/envs/ensf-ml/lib/python3.10/site-packages/sklearn/svm/_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/mehreen/anaconda3/envs/ensf-ml/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/mehreen/anaconda3/envs/ensf-ml/lib/python3.10/site-packages/sklearn/svm/_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/mehreen/anaconda3/envs/ensf-ml/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score = 0.9247928055016752 \n",
      " Validation score = 0.8874643874643875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mehreen/anaconda3/envs/ensf-ml/lib/python3.10/site-packages/sklearn/svm/_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "linear_svm = LinearSVC(max_iter = 5000)\n",
    "scores = cross_validate(linear_svm, X_train, y_train, cv=5, \n",
    "                        scoring='accuracy',\n",
    "                    return_train_score=True)\n",
    "train_score = scores['train_score'].mean()\n",
    "validation_score = scores['test_score'].mean()\n",
    "print(\"Train score = {} \\n Validation score = {}\".format(train_score, validation_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aabc68a4",
   "metadata": {},
   "source": [
    "*ANSWER HERE*\n",
    "\n",
    "LinearSVC results : Train_score: 0.91, validation score = 0.86. \n",
    "Part 2 SVC result : Train_score: 0.71, validation score = 0.68.\n",
    "\n",
    "LinearSVC model performed better than the SVC model in part 2. The training and validation accuracy are a lot higher and closer to 1 in comparison. Therefore, using LinearSVC did improve the results ( 0.71 to 0.91 for training ) and (0.68 to 0.86 for validation score) both scores increased. The model is better at generalizing the data and predicting unseen data. This is because the data needs scaling so a linear model would perform better then a SVM model. \n",
    "\n",
    "LinearSVC is not a good fit for this data becuase the maximum iteration is reached. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241c3b12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
